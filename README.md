# Лабораторный проект: Задача классификации (Diabetes Dataset)

## Цель
Построить и оценить модель классификации поверх очищенного датасета из ЛР-1; освоить базовые и продвинутые алгоритмы, метрики, интерпретацию, анализ ошибок.

## Участники и файлы
| Участник | Роль | Ноутбук |
|----------|------|---------|
| Роман | Повторная загрузка и pipeline + Разбиение и валидация| 01_data_preparation_and_pipeline.ipynb |
| Максим | Базовые модели | 02_baseline_models_logreg_dt.ipynb |
| Кирилл | Продвинутая модель и поиск гиперпараметров | 03_advanced_model_xgb_lgb_cb.ipynb |
| Стас | Интерпретация и анализ ошибок | 04_explainability_error_analysis.ipynb |
| Илья | Репродуцируемость + отчет + ревью | 05_final_assembly_and_qc.ipynb |

## Структура проекта
```
notebooks/        — отдельный ноутбук под каждый этап  
data/raw/         — исходные данные (diabetes.csv)  
data/interim/     — промежуточные (например, diabetes_stage1.csv)  
src/              — вспомогательные функции (опционально)
```

## Данные
Источник: Использовать очищенный датасет из лабораторной работы 1 (заполнение пропусков + нормализация + винсоризация выбросов ). Pima Indians Diabetes (UCI / Kaggle).  
Файл: `data/raw/diabetes_clean.csv`.  

## Мини чек-лист

### Данные и Pipeline
- [x] Использую очищенный датасет из ЛР-1  
- [x] Все преобразования собраны в sklearn Pipeline/ColumnTransformer  
- [x] fit только на train (импьютация/скейлер/one-hot) – утечек нет  
- [x] Список признаков и стратегия пропусков зафиксированы и описаны  

### Разбиение / валидация
- [x] Stratified train/valid/test = 60/20/20, random_state=42  
- [x] При CV: StratifiedKFold(shuffle=True, random_state=42)  
- [x] Test не трогаю до финального выбора модели/порога  

### Базовые модели
- [x] Обучены LogisticRegression и DecisionTree (подобран max_depth)  
- [x] Метрики на valid: F1 + ROC-AUC (и PR-AUC, если позитивов < 30%)  
- [x] Краткий вывод: какая baseline-модель лучше и почему  

### Продвинутая модель
- [ ] Одна из: CatBoost / LightGBM / XGBoost  
- [ ] Поиск 5–10 конфигураций (Grid/Random/SearchCV) с логом результатов  
- [ ] Сравнение с baseline — выбран «победитель»  

### Интерпретация и ошибки
- [ ] SHAP (summary + 1–2 waterfall) или permutation importance  
- [ ] Показаны минимум 3 FN и 3 FP с кратким разбором причин и идеями улучшения  

### Репродуцируемость
- [ ] Зафиксировал random_state/seed  
- [ ] Вывел версии библиотек  
- [ ] Убедился, что ноутбук запускается без ошибок  


## Дальнейшие шаги
- После завершения всех этапов можно объединить выводы в один отчёт (PDF/DOCX).
